{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Architecture and Training\n",
    "\n",
    "Due to large file sizes for both the data used to train each of the CNN models and the models themselves, neither the models nor the full datasets have been uploaded to Github. Instead, only the code for encoding the images through VGG16 (which has been commented out purposefully) and training the CNN models is given here. Note that even though height is the target trait in this code, the same network architecture was used for all models trained in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as k\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Data set-up - because files are too large, these lines are included only to show how the training and testing data sets\n",
    "were constructed. Note that random splitting into training and testing sets occurred prior to this step, so training images\n",
    "were stored first follwed by test images.\"\"\"\n",
    "\n",
    "#vg = k.applications.vgg16.VGG16(include_top=False, input_shape=(1028,1227,3))\n",
    "#encd_img = np.zeros((2000,32,38,512))\n",
    "#for i in range(2000):\n",
    "#    img_test = np.divide(cv2.imread('C:/Users/jason/Documents/Soy/SoyImg'+str(i)+'.png'),255)\n",
    "#    i_test = np.zeros((1,1028,1227,3))\n",
    "#    i_test[0,:,:,:] = img_test\n",
    "#    encd_img[i,:,:,:] = vg.predict(i_test)\n",
    "\n",
    "#soy_hts = np.loadtxt('C:/Users/jason/Documents/Soy/Data/hts_from_seg.txt')\n",
    "#soy_train = encd_img[0:1800,:,:,:]\n",
    "#soy_test = encd_img[1800:2000,:,:,:]\n",
    "#hts_train = soy_hts[0:1800]\n",
    "#hts_test = soy_hts[1800:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Create model architecture into which encoded images can be fed###\n",
    "soy_vgg = k.models.Sequential()\n",
    "soy_vgg.add(k.layers.Flatten(data_format = 'channels_last',input_shape = (32,38,512)))\n",
    "soy_vgg.add(k.layers.Dense(64,activation='relu'))\n",
    "soy_vgg.add(k.layers.Dense(64,activation='relu'))\n",
    "soy_vgg.add(k.layers.Dense(1,activation='linear'))\n",
    "#soy_vgg.summary()  #used to view a summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Model compilation - adam optimizer, mse loss function, and tracking mae through training###\n",
    "soy_vgg.compile(loss = 'mse',optimizer = k.optimizers.adam(0.0008), metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Model training - validation split = 0.1111 holds out 1/9 (200) of the training images as validation images###\n",
    "\n",
    "#hist = soy_vgg.fit(soy_train, hts_train, epochs = 100, batch_size = 128, validation_split = 0.1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Model prediction on test images - with large enough RAM, this section of code could simply be soy_vgg.predict(soy_test).\n",
    "However, because of the large RAM requirements, it was necessary for us predict on each image individually. Because the \n",
    "model is trained on a four-dimensional array (one dimension each for the number of images, height, width, and channels), \n",
    "a four-dimensional array was required as input. Thus such an array is first constructed for each image in the test set \n",
    "before prediction takes place.\"\"\"\n",
    "pred_hts = np.zeros(200)\n",
    "for i in range(200):\n",
    "    img_in = np.zeros((1,32,38,512))\n",
    "    img_in[0,:,:,:] = soy_test[i,:,:,:]\n",
    "    pred_hts[i] = soy_vgg.predict(img_in)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
